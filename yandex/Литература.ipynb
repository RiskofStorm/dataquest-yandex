{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы составили для вас список наших любимых учебников по темам, рассматривавшимся в этом курсе, с короткими комментариями.\n",
    "Линейная алгебра\n",
    "\n",
    "Виктор Кантор:\n",
    "\n",
    "    Ильин, Ким. Линейная алгебра и аналитическая геометрия (1998) — МГУ.\n",
    "    Умнов. Аналитическая геометрия и линейная алгебра (2011) — МФТИ.\n",
    "\n",
    "Евгений Рябенко:\n",
    "\n",
    "Деммель. Вычислительная линейная алгебра. Теория и приложения (2001) — понятный кусок про матричные разложения.\n",
    "Математический анализ\n",
    "\n",
    "Виктор Кантор:\n",
    "\n",
    "    Ильин, Позняк, Основы математического анализа (2005) — МГУ.\n",
    "    Тер-Крикоров, Шабунин. Курс математического анализа (2001) — МФТИ, много примеров.\n",
    "    Иванов. Лекции по математическому анализу (2000) — МФТИ, очень короткое, но полное изложение.\n",
    "\n",
    "Методы оптимизации\n",
    "\n",
    "Евгений Рябенко:\n",
    "\n",
    "    Нестеров. Методы выпуклой оптимизации (2010) — математически строгое введение в оптимизацию от живого классика.\n",
    "    Boyd, Vandenberghe. Convex Optimization (2004) — идеальная книга по классической оптимизации, много интересных постановок задач.\n",
    "    Schneider, Kirkpatrick. Stochastic Optimization (2006) — стохастическая оптимизация во всём многообразии.\n",
    "\n",
    "Теория вероятностей и статистика\n",
    "\n",
    "Евгений Соколов:\n",
    "\n",
    "    Dekking, Kraaikamp, Lopuhaa, Meester. A Modern Introduction to Probability and Statistics, Understanding Why and How (2005) — доступная книга, описывающая базовые понятия, теоремы и методы; разбирается очень много примеров, тесно связанных с задачами машинного обучения и анализа данных.\n",
    "\n",
    "Виктор Кантор:\n",
    "\n",
    "    Лагутин. Наглядная математическая статистика (2007) — в основном статистика, но есть и небольшое введение в теорию вероятностей. Стоит читать, кроме глав про классификацию и анализ данных, там изложение не слишком современно.\n",
    "    Чжун, АитСахлиа. Элементарный курс теории вероятностей. Стохастические процессы и финансовая математика (2007) — очень простое изложение.\n",
    "    Отличные лекции с мехмата Новосибирского Государственного Университета: http://www.nsu.ru/mmf/tvims/chernova/tv/tv_nsu07.pdf — теория вероятностей, http://www.nsu.ru/mmf/tvims/chernova/ms/ms_nsu07.pdf — математическая статистика.\n",
    "\n",
    "Евгений Рябенко:\n",
    "\n",
    "    Diez, Barr, Çetinkaya-Rundel, Dorazio. Advanced High School Statistics (2015) — вводная книга, программа соответствует типичному курсу Statistics 101 хорошего западного университета.\n",
    "    DasGupta. Probability for Statistics and Machine Learning: Fundamentals and Advanced Topics (2011) — для смелого читателя, рассматриваются в том числе достаточно высокоуровневые методы.\n",
    "\n",
    "Python\n",
    "\n",
    "Эмели Драль:\n",
    "\n",
    "    Классические руководства по Python: https://docs.python.org/2/tutorial/ (2.7), https://docs.python.org/3/tutorial/ (3.5)\n",
    "    Reitz. The Hitchhiker’s Guide to Python http://docs.python-guide.org/en/latest/ — довольно полное руководство, в котором рассматриваются вопросы от установки, работы с виртуальным окружением и работы в различных IDE до основных структур языка с примерами кода.\n",
    "    Google python class https://developers.google.com/edu/python/ — небольшой бесплатный онлайн-курс по Python для слушателей с минимальным опытом программирования.\n",
    "\n",
    "Книги для тех, кому захочется основательно изучить Python:\n",
    "\n",
    "    Lutz. Learning Python (2013) — с этой книги можно начинать изучение, она покрывает все основные структуры языка.\n",
    "    Lutz. Python Pocket Reference (2015) — подробный справочник.\n",
    "\n",
    "Обе эти книги переведены на русский."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы составили для вас список наших любимых учебников по темам, рассматривавшимся в этом курсе, с короткими комментариями.\n",
    "\n",
    "(Лучше всего изучать прямо в такой последовательности)\n",
    "\n",
    "    Hastie, Tibshirani, Friedman. The elements of statistical learning — классический способ начать знакомиться с машинным обучением, если вас не пугает математика\n",
    "    Bishop. Pattern recognition and machine learning — (чрезмерно) подробный справочник методов, дающий возможность познакомиться, например, с десятью версиями метода главных компонент\n",
    "    Murphy. Machine learning a probabilistic perspective — очень объемная и содержательная книга из MIT (~1000 страниц), освещена большая часть мейнстримовых методов машинного обучения.\n",
    "\n",
    "Если в начале математика в The elements of statistical learning покажется сложной, можно попробовать облегчённую версию учебника от тех же авторов —James, Witten, Hastie, Tibshirani. An Introduction to Statistical Learning.\n",
    "\n",
    "Если хочется на русском, то можно начать с лекций Константина Вячеславовича Воронцова по машинному обучению. Но решающие деревья в этом случае лучше изучить по User Guide scikit-learn, а градиентный бустинг и случайный лес — все-таки по The elements of statistical learning.\n",
    "\n",
    "Если до погружения в математику хочется понять на инженерном уровне “что как работает”, то для этого хорошо подойдут:\n",
    "\n",
    "    Harrington. Machine Learning in Action — дается базовое знакомство с методами машинного обучения, без перегрузки математическими деталями\n",
    "    Marshland. Machine Learning: An Algorithmic Perspective — приводятся и объясняются реализации разных методов машинного обучения на Python\n",
    "    Richert, Coelho. Building Machine Learning Systems with Python — очень доступное изложение разных задач машинного обучения (анализ изображений, текстов, звука) с описанием того, как это сделать в Python (прямо с кодом)\n",
    "\n",
    "Отдельно про нейросети можно почитать:\n",
    "\n",
    "    Хайкин. Нейронные сети. Полный курс\n",
    "    Goodfellow, Bengio, Courville. Deep Learning (для сильных духом любителей складывать слои как блинчики)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
