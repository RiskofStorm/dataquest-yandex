{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pprint as pp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# uncomment and run it first!\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load nlp_process_data.py\n",
    "\n",
    "def build_pipe(vect, model, stopwords=None, ngram_range=(1,1), analyzer='word'):\n",
    "    return Pipeline([(\"count\", vect(stop_words=stopwords, ngram_range=ngram_range, analyzer=analyzer)),\n",
    "                     (\"model\", model())])\n",
    "\n",
    "\n",
    "def train_test_models(X_train, y_train, models_cls=None, vectorizer_cls=None, \n",
    "                      random_state=None, min_df=None,stopwords=None,\n",
    "                      ngram_range=(1,1), analyzer='word',\n",
    "                      vectorizer_names=None, model_names=None):\n",
    "    results = list()\n",
    "    mean = list()\n",
    "    if not models_cls or not vectorizer_names:\n",
    "        models_cls = [LogisticRegression,\n",
    "                      RandomForestClassifier,\n",
    "                      LinearSVC,\n",
    "                      SGDClassifier]\n",
    "        model_names = [\"LogReg\", \"RF Clas.\", \"LinearSVC\", \"SGD Clas.\"]\n",
    "    if not vectorizer_cls or not model_names:\n",
    "        vectorizer_cls = [TfidfVectorizer, CountVectorizer]\n",
    "        vectorizer_names = [\"TfidfVec\", \"CntVec\"]\n",
    "       \n",
    "    _vectorizer_names = iter(vectorizer_names)\n",
    "    for vectorizer in vectorizer_cls:\n",
    "        vector_name = _vectorizer_names.__next__()\n",
    "        _model_names = iter(model_names)\n",
    "        for model in models_cls:\n",
    "            pipe = build_pipe(vectorizer, model, stopwords=stopwords,\n",
    "                              ngram_range=ngram_range, analyzer=analyzer)\n",
    "            score = cross_val_score(pipe, X_train, y_train, scoring='accuracy')\n",
    "            mean.append(np.mean(score))\n",
    "            \n",
    "            results.append(\"model: {}, vectorizer: {}  \\\n",
    "                            scores: {}, mean: {}\".format(_model_names.__next__(),\n",
    "                                                         vector_name, score,\n",
    "                                                         round(np.mean(score),4)))    \n",
    "    return results, mean\n",
    "\n",
    "def text_preprocessing(series):\n",
    "    for i in range(series.shape[0]):\n",
    "        text = series.iloc[i]\n",
    "        pattern = re.compile(r\"(?u)\\w+\")\n",
    "        series.iloc[i] = re.findall(pattern, text.lower())\n",
    "    return series\n",
    "\n",
    "def process_data(data, func):\n",
    "    # Removing all words what is less than 3 letters\n",
    "    series = data.copy()\n",
    "    for i in range(data.shape[0]):\n",
    "        series.iloc[i] = \" \".join([func(w) for w in data.iloc[i]])\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2311, 2)\n",
      "1.0    1783\n",
      "0.0     528\n",
      "Name: mark, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "path = \"/media/winter/vm/github/kaggle/Product_Sentiment/\"\n",
    "data = open(path+\"test.csv\", \"r\").readlines()\n",
    "\n",
    "data = \" \".join(data).split(\"</review>\")[:-1]\n",
    "X_test = [text.replace('<review>', \"\").replace(\"\\n\", \"\") for text in data]\n",
    "stop_words = stopwords.words('russian')\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"reviews_yandexmarket_aws.csv\", sep=',',header=None, names=['mark','rev'])\n",
    "data2 = pd.read_csv(\"reviews_yandexmarket_old.csv\", sep=',',header=None, names=['mark','rev'])\n",
    "data3 = pd.read_csv(\"reviews_yandexmarket_1.csv\", sep=',',header=None, names=['mark','rev'])\n",
    "data4 = pd.read_csv(\"reviews_yandexmarket.csv\", sep=',',header=None, names=['mark','rev'])\n",
    "full_data = data.append([data2, data3, data4])\n",
    "full_data.dropna(inplace=True)\n",
    "\n",
    "# sample = full_data[full_data[\"mark\"]==1].sample(528)\n",
    "# sample = sample.append(full_data[full_data[\"mark\"]==0])\n",
    "# sample.reset_index(inplace=True)\n",
    "# print(sample['mark'].value_counts())\n",
    "print(full_data.shape)\n",
    "print(full_data['mark'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = full_data['rev'].copy(), full_data['mark'].copy()\n",
    "X_test_ = X_test.copy() \n",
    "\n",
    "# sX_train corrected sampled X_train to sustain equality of frequency in binary classification\n",
    "\"\"\"\n",
    "WordNetLemmatizer().lemmatize\n",
    "SnowballStemmer('russian').stem\n",
    "PorterStemmer().stem\n",
    "\"\"\"\n",
    "X_train_ = text_preprocessing(X_train)\n",
    "X_train_ = process_data(X_train_, PorterStemmer().stem)\n",
    "\n",
    "## dict is had about 4k words\n",
    "# X_sample_train, y_sample_train = sample['rev'].copy(), sample['mark'].copy()\n",
    "# sX_train_ = text_preprocessing(X_sample_train)\n",
    "# sX_train_ = process_data(sX_train_, PorterStemmer().stem)\n",
    "# sy_train = sample['mark']\n",
    "\n",
    "X_test_ = text_preprocessing(pd.Series(X_test))\n",
    "X_test_ = process_data(pd.Series(X_test_), PorterStemmer().stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score:  0.9943747295543055\n",
      "cross score:  [0.75862069 0.83189655 0.93103448 0.94805195 0.8961039  0.995671\n",
      " 0.995671   0.87012987 0.73478261 0.71304348] mean:  0.8675005516722158\n",
      "vocab capacity: 8324\n"
     ]
    }
   ],
   "source": [
    "# model = RandomForestClassifier(n_estimators=250, max_depth=5)\n",
    "\n",
    "# model = xgb.XGBClassifier(learning_rate=0.1, max_depth=5, n_estimators=250, min_child_weight=2,\n",
    "#                           n_jobs=4)\n",
    "\n",
    "model = LogisticRegression(max_iter=10000, penalty='l2', \n",
    "                           class_weight={0:1.15,1:1}, solver='liblinear', n_jobs=3)\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3), min_df=5, stop_words=stop_words)\n",
    "\n",
    "\n",
    "X_train__ = X_train_.copy()\n",
    "y_train = y_train.copy()\n",
    "kaggle_X_test_ = X_test_.copy()\n",
    "\n",
    "vectorizer.fit(X_train__)\n",
    "X_train_transf = vectorizer.transform(X_train__)\n",
    "model.fit(X_train_transf, y_train)\n",
    "model_pred = model.predict(X_train_transf)\n",
    "\n",
    "model_acc = accuracy_score(y_train, model_pred)\n",
    "cross_acc = cross_val_score(model, X_train_transf, y_train, scoring='accuracy', cv=10)\n",
    "\n",
    "print(\"model score: \", model_acc)\n",
    "print(\"cross score: \", cross_acc,\"mean: \", np.mean(cross_acc))\n",
    "print(\"vocab capacity:\",len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_predict = ['pos' if i else 'neg' for i in model.predict(vectorizer.transform(kaggle_X_test_))]\n",
    "submit = pd.DataFrame({'y':sub_predict})\n",
    "submit.index.name='id'\n",
    "submit.to_csv(\"submission.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x265 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2397 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(X_train__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth (int) – Maximum tree depth for base learners.\n",
    "learning_rate (float) – Boosting learning rate (xgb’s “eta”)\n",
    "n_estimators (int) – Number of trees to fit.\n",
    "verbosity (int) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
    "silent (boolean) – Whether to print messages while running boosting. Deprecated. Use verbosity instead.\n",
    "objective (string or callable) – Specify the learning task and the corresponding learning objective or a custom objective function to be used (see note below).\n",
    "booster (string) – Specify which booster to use: gbtree, gblinear or dart.\n",
    "nthread (int) – Number of parallel threads used to run xgboost. (Deprecated, please use n_jobs)\n",
    "n_jobs (int) – Number of parallel threads used to run xgboost. (replaces nthread)\n",
    "gamma (float) – Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "min_child_weight (int) – Minimum sum of instance weight(hessian) needed in a child.\n",
    "max_delta_step (int) – Maximum delta step we allow each tree’s weight estimation to be.\n",
    "subsample (float) – Subsample ratio of the training instance.\n",
    "colsample_bytree (float) – Subsample ratio of columns when constructing each tree.\n",
    "colsample_bylevel (float) – Subsample ratio of columns for each level.\n",
    "colsample_bynode (float) – Subsample ratio of columns for each split.\n",
    "reg_alpha (float (xgb's alpha)) – L1 regularization term on weights\n",
    "reg_lambda (float (xgb's lambda)) – L2 regularization term on weights\n",
    "scale_pos_weight (float) – Balancing of positive and negative weights.\n",
    "base_score – The initial prediction score of all instances, global bias.\n",
    "seed (int) – Random number seed. (Deprecated, please use random_state)\n",
    "random_state (int) – Random number seed. (replaces seed)\n",
    "missing (float, optional) – Value in the data which needs to be present as a missing value. If None, defaults to np.nan.\n",
    "importance_type (string, default \"gain\") – The feature importance type for the feature_importances_ property: either “gain”, “weight”, “cover”, “total_gain” or “total_cover”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_1 = list()\n",
    "# test_1.append(train_test_models(X_train_, y_train, ngram_range=(1,3), min_df=5))\n",
    "# test_1.append(train_test_models(X_train_, y_train, ngram_range=(1,4), min_df=5))\n",
    "# test_1.append(train_test_models(X_train_, y_train, ngram_range=(1,2), min_df=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    y\n",
       "0    0  pos\n",
       "1    1  pos\n",
       "2    2  pos\n",
       "3    3  pos\n",
       "4    4  pos\n",
       "5    5  pos\n",
       "6    6  pos\n",
       "7    7  pos\n",
       "8    8  pos\n",
       "9    9  pos\n",
       "10  10  pos\n",
       "11  11  pos\n",
       "12  12  pos\n",
       "13  13  pos\n",
       "14  14  pos\n",
       "15  15  pos\n",
       "16  16  pos\n",
       "17  17  pos\n",
       "18  18  pos\n",
       "19  19  pos\n",
       "20  20  pos\n",
       "21  21  pos\n",
       "22  22  pos\n",
       "23  23  pos\n",
       "24  24  pos\n",
       "25  25  pos\n",
       "26  26  pos\n",
       "27  27  pos\n",
       "28  28  pos\n",
       "29  29  pos\n",
       "..  ..  ...\n",
       "70  70  pos\n",
       "71  71  pos\n",
       "72  72  pos\n",
       "73  73  neg\n",
       "74  74  pos\n",
       "75  75  pos\n",
       "76  76  pos\n",
       "77  77  pos\n",
       "78  78  pos\n",
       "79  79  pos\n",
       "80  80  neg\n",
       "81  81  pos\n",
       "82  82  pos\n",
       "83  83  pos\n",
       "84  84  pos\n",
       "85  85  pos\n",
       "86  86  pos\n",
       "87  87  pos\n",
       "88  88  neg\n",
       "89  89  pos\n",
       "90  90  pos\n",
       "91  91  pos\n",
       "92  92  pos\n",
       "93  93  pos\n",
       "94  94  pos\n",
       "95  95  neg\n",
       "96  96  pos\n",
       "97  97  neg\n",
       "98  98  pos\n",
       "99  99  pos\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting parse_yandex_market.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile parse_yandex_market.py\n",
    "# import pickle\n",
    "# from multiprocessing import Pool\n",
    "# import time\n",
    "# import random\n",
    "# import requests\n",
    "# import bs4\n",
    "\n",
    "# def parse_page(url):\n",
    "#     time.sleep(random.randint(5,30))\n",
    "    \n",
    "#     text = requests.get(url)\n",
    "#     text.encoding = \"utf-8\"\n",
    "    \n",
    "#     parser = bs4.BeautifulSoup(text.text, 'lxml')\n",
    "#     data = parser.findAll('div', attrs={\"class\":\"n-snippet-card-review__right\"})\n",
    "    \n",
    "#     full_revs = [\" \".join([t.text for t in i.find_all('dd')]) for i in data]\n",
    "\n",
    "#     rating_revs = [1 if float(i.text) > 3 else 0  for i in \n",
    "#                    parser.findAll('div', attrs={'class':'rating__value'})]\n",
    "    \n",
    "#     return list(zip(full_revs, rating_revs))\n",
    "\n",
    "# url = \"\"\"https://market.yandex.ru/catalog--mobilnye-telefony-otzyvy-pokupatelei/54726/list?\\\n",
    "# show-reviews=1&page={}&local-offers-first=0&onstock=0&how=quality\"\"\"\n",
    "\n",
    "# pool = Pool(3)\n",
    "# url_list = [url.format(i) for i in range(2,51)]\n",
    "# url_list_2 = [url.format(i) for i in range(52,151)]\n",
    "# if __name__ == \"__main__\":\n",
    "#     map_results = pool.map(parse_page, url_list)\n",
    "#     with open('parsing_revievs_yandexMarket','wb') as out_f:\n",
    "#         pickle.dump(map_results, out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile parse_YM.py\n",
    "# import pickle\n",
    "# from multiprocessing import Pool\n",
    "# import time\n",
    "# import random\n",
    "# import requests\n",
    "# import bs4\n",
    "\n",
    "# def parse_page(url):\n",
    "#     time.sleep(random.randint(15,120))\n",
    "    \n",
    "#     text = requests.get(url)\n",
    "#     text.encoding = \"utf-8\"\n",
    "    \n",
    "#     parser = bs4.BeautifulSoup(text.text, 'lxml')\n",
    "#     data = parser.findAll('div', attrs={\"class\":\"n-snippet-card-review__right\"})\n",
    "    \n",
    "#     full_revs = [\" \".join([t.text for t in i.find_all('dd')]) for i in data]\n",
    "\n",
    "#     rating_revs = [1 if float(i.text) > 3 else 0  for i in \n",
    "#                    parser.findAll('div', attrs={'class':'rating__value'})]\n",
    "#     return list(zip(full_revs, rating_revs))\n",
    "\n",
    "# url = \"\"\"https://market.yandex.ru/catalog--mobilnye-telefony-otzyvy-pokupatelei/54726/list?\\\n",
    "# show-reviews=1&page={}&local-offers-first=0&onstock=0&how=quality\"\"\"\n",
    "\n",
    "# new_url = \"\"\"https://market.yandex.ru/catalog--mobilnye-telefony-otzyvy-pokupatelei/54726/list?\\\n",
    "# show-reviews=1&local-offers-first=0&onstock=0&deliveryincluded=0&page={}\"\"\"\n",
    "\n",
    "\n",
    "# pool = Pool(10)\n",
    "# url_list = [url.format(i) for i in range(2,51)]\n",
    "# url_list_2 = [new_url.format(i) for i in range(1,52)]\n",
    "# if __name__ == \"__main__\":\n",
    "#     map_results = list(map(parse_page, url_list_2))\n",
    "#     with open('parsing_revievs_yandexMarket_NEWS','wb') as out_f:\n",
    "#         pickle.dump(map_results, out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('parsing_revievs_yandexMarket_NEWS','rb') as in_f:\n",
    "#     new_data = pickle.load(in_f)\n",
    "# unpack = [sent for nest in new_data for sent in nest]\n",
    "# X_train_neg = [i[0] for i in unpack ]\n",
    "# y_train_neg = [i[1] for i in unpack ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
